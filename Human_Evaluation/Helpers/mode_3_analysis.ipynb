{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import pos_tag, word_tokenize\n",
    "import re\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data size of 909 reduced to -> 155\n"
     ]
    }
   ],
   "source": [
    "### Human Evaluator Verified Dataset\n",
    "data = pd.read_csv(\"output_mode_2_only_valid_questions.csv\")\n",
    "og_data_size = len(data)\n",
    "\n",
    "df_gp = data[[\"group\", \"prefix\"]]\n",
    "df_gp = df_gp.drop_duplicates(subset=[\"prefix\"])\n",
    "print(f\"Original Data size of {og_data_size} reduced to -> {len(df_gp)}\")\n",
    "\n",
    "# group by the first part of the prefix - e.g 3000\n",
    "df_gp['prefix'], df_gp['index'] = zip(*df_gp['prefix'].str.split('_').apply(lambda x: (x[0], x[1])))\n",
    "df_gp['index'] = df_gp['index'].astype(int) - 1\n",
    "df_gp['group'] = df_gp['group'].str.split('_').str[0]\n",
    "df_gp = df_gp.groupby(['group', 'prefix'])['index'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Human Evaluator Verified Dataset\n",
    "# algorithm to parse through each group and every prefix to collect a list of OQ/OA/CA/FUQS\n",
    "full_path = '/Users/tkang/Documents/research/nlp_followupqg/Auto_Evaluation/full_clustered.json'\n",
    "gpt_path = '/Users/tkang/Documents/research/nlp_followupqg/Auto_Evaluation/gpt_clustered.json'\n",
    "org_path = '/Users/tkang/Documents/research/nlp_followupqg/Auto_Evaluation/org_clustered.json'\n",
    "\n",
    "# Load data\n",
    "full_df = pd.read_json(full_path)\n",
    "gpt_df = pd.read_json(gpt_path)\n",
    "org_df = pd.read_json(org_path)\n",
    "\n",
    "filtered_data_full = pd.DataFrame(columns=full_df.columns)\n",
    "filtered_data_gpt = pd.DataFrame(columns=gpt_df.columns)\n",
    "filtered_data_org = pd.DataFrame(columns=org_df.columns)\n",
    "\n",
    "json_df = None\n",
    "\n",
    "# Explode the `generated_follow_up` column\n",
    "# json_data = json_data.explode('generated_follow_up', ignore_index=True)\n",
    "\n",
    "for index, row in df_gp.iterrows():\n",
    "    match row['group']:\n",
    "        case 'full':\n",
    "            json_df = full_df\n",
    "        case 'gpt':\n",
    "            print()\n",
    "            json_df = gpt_df\n",
    "        case 'org':\n",
    "            json_df = org_df\n",
    "        case _:\n",
    "            print(\"Invalid File Found\")\n",
    "            json_df = None\n",
    "            break\n",
    "    \n",
    "    for _, json_data in json_df.iterrows():\n",
    "        if int(json_data['id']) != int(row['prefix']):\n",
    "            continue\n",
    "        \n",
    "        relevant_follow_ups = np.array(json_data['generated_follow_up'])\n",
    "        relevant_follow_ups = relevant_follow_ups[row['index']]\n",
    "        row_data = json_data\n",
    "        row_data['generated_follow_up'] = relevant_follow_ups\n",
    "\n",
    "        match row['group']:\n",
    "            case 'full':\n",
    "                filtered_data_full.loc[len(filtered_data_full)] = row_data\n",
    "            case 'gpt':\n",
    "                filtered_data_gpt.loc[len(filtered_data_gpt)] = row_data\n",
    "            case 'org':\n",
    "                filtered_data_org.loc[len(filtered_data_org)] = row_data\n",
    "            case _:\n",
    "                print(\"Invalid File Found\")\n",
    "                break\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Entire Dataset Collected by Each of the 3 Models\n",
    "full_path = '/Users/tkang/Documents/research/nlp_followupqg/Auto_Evaluation/full_clustered.json'\n",
    "gpt_path = '/Users/tkang/Documents/research/nlp_followupqg/Auto_Evaluation/gpt_clustered.json'\n",
    "org_path = '/Users/tkang/Documents/research/nlp_followupqg/Auto_Evaluation/org_clustered.json'\n",
    "\n",
    "# Load data\n",
    "full_df = pd.read_json(full_path)\n",
    "gpt_df = pd.read_json(gpt_path)\n",
    "org_df = pd.read_json(org_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/tkang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/tkang/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Methods to Determine if a Sentence is a valid question\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Define a regex pattern to match informative questions\n",
    "invalid_words_pattern = r'<\\w+>'\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def contains_question_mark(sentence, invalid_questions):\n",
    "    if sentence[-1] == '?':\n",
    "        return True\n",
    "    else:\n",
    "        invalid_questions.append(sentence)\n",
    "        return False\n",
    "\n",
    "def is_question_dependency_parsing(sentence, invalid_questions):\n",
    "    \"\"\"Detects whether a sentence is a question using dependency parsing.\"\"\"\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    # Track question indicators\n",
    "    is_wh_question = False\n",
    "    is_aux_question = False\n",
    "    \n",
    "    # ‚úÖ Track negation but don't invalidate questions outright\n",
    "    # negation_found = any(token.dep_ == \"neg\" for token in doc)\n",
    "\n",
    "    for token in doc:\n",
    "        # ‚úÖ WH-Questions (What, Why, How, Where, etc.)\n",
    "        if token.dep_ in {\"attr\", \"nsubj\", \"advmod\"} and token.head.dep_ in {\"ROOT\", \"nsubj\", \"advmod\"}:\n",
    "            is_wh_question = True\n",
    "        \n",
    "        # ‚úÖ Yes/No Questions (Do you..., Can we..., Is it...)\n",
    "        if token.dep_ == \"aux\" and token.head.dep_ == \"ROOT\":\n",
    "            is_aux_question = True\n",
    "        \n",
    "        # ‚úÖ Special Case: \"Why\", \"How\", \"Where\" directly at the start are always questions\n",
    "        if token.text.lower() in {\"why\", \"how\", \"where\"}:\n",
    "            is_wh_question = True\n",
    "    \n",
    "    # ‚úÖ Final Decision:\n",
    "    if not (is_wh_question or is_aux_question):\n",
    "        # üî• **NEW: Only invalidate if negation makes it rhetorical**  \n",
    "        invalid_questions.append(sentence)\n",
    "        return False  # Negation in non-WH questions is more likely rhetorical\n",
    "    # ‚ùå Not a valid question\n",
    "    return True\n",
    "\n",
    "def contains_invalid_word(question, invalid_questions):\n",
    "    if bool(re.search(invalid_words_pattern, question)):\n",
    "        invalid_questions.append(question)\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def get_consecutive_word_sequences(sentence):\n",
    "    \"\"\"Extracts consecutive word sequences of at least `min_length` words.\"\"\"\n",
    "    min_length = int(len(sentence.split(\" \"))/2) # if a sentence uses over half of it's words, it's copying\n",
    "    words = re.findall(r'\\b\\w+\\b', sentence)  # Extract words\n",
    "    sequences = set()\n",
    "\n",
    "    for i in range(len(words) - min_length + 1):\n",
    "        phrase = \" \".join(words[i:i + min_length])  # Create word sequence\n",
    "        sequences.add(phrase)\n",
    "\n",
    "    return sequences\n",
    "\n",
    "def contains_duplicate_words(og_question, og_answer, follow_up_question, invalid_questions):\n",
    "    \"\"\"Checks if there is a common substring of at least `min_length` consecutive words between two sentences.\"\"\"\n",
    "    og_question_answer = og_question + \" \" + og_answer  # Merge question and answer\n",
    "    \n",
    "    og_seq = get_consecutive_word_sequences(og_question_answer)\n",
    "    follow_up_seq = get_consecutive_word_sequences(follow_up_question)\n",
    "\n",
    "    common_sequences = og_seq & follow_up_seq  # Only allow consecutive matches\n",
    "\n",
    "    if common_sequences:\n",
    "        invalid_questions.append(follow_up_question)\n",
    "        return True  # Found duplicate consecutive words\n",
    "    return False\n",
    "\n",
    "# combining all the other methods\n",
    "def is_valid_question(question, og_question, og_answer, invalid_questions):\n",
    "    # print(question)\n",
    "    return (\n",
    "        contains_question_mark(question, invalid_questions) and \n",
    "        is_question_dependency_parsing(question, invalid_questions) and \n",
    "        not contains_invalid_word(question, invalid_questions) and\n",
    "        not contains_duplicate_words(og_question, og_answer, question, invalid_questions)\n",
    "        )\n",
    "\n",
    "def filterInvalidFollowUpQuestions(df):\n",
    "    # df columns = ['id', 'question', 'answer', 'follow-up', 'relation', 'generated_follow_up']\n",
    "    invalid_questions = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        original_question = row['question']\n",
    "        original_answer = row['answer']\n",
    "\n",
    "        valid_questions = [follow_up for follow_up in row['generated_follow_up'] if is_valid_question(follow_up, original_question, original_answer, invalid_questions)]\n",
    "        df.at[index, \"generated_follow_up\"] = valid_questions\n",
    "    \n",
    "    return df, invalid_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# og_question = \"ELI5: What is a heat dome?\"\n",
    "# og_answer = \"Is when the high pressure in the atmosphere traps the hot air in below. As you would know, the hot air rises, which only causes the air to compress because of the pressure from above and it gets hotter, hotter, hotter and denser (That's why you would kill for a glass of water, the hot air is literally pushing you against more hot air)\"\n",
    "# question = \">That's why you would kill for a glass of water  Is that why people die from heatstroke?\"\n",
    "\n",
    "# contains_duplicate_words(og_question, og_answer, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_json(\"full_df.json\", orient=\"records\", indent=4)\n",
    "gpt_df.to_json(\"gpt_df.json\", orient=\"records\", indent=4)\n",
    "org_df.to_json(\"org_df.json\", orient=\"records\", indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before filtering out all invalid follow up questions in FULL: 2061\n",
      "after filtering out all invalid follow up questions in FULL: 1956\n",
      "before filtering out all invalid follow up questions in GPT: 1895\n",
      "after filtering out all invalid follow up questions in GPT: 1831\n",
      "before filtering out all invalid follow up questions in ORG: 2349\n",
      "after filtering out all invalid follow up questions in ORG: 1869\n"
     ]
    }
   ],
   "source": [
    "print(f\"before filtering out all invalid follow up questions in FULL: { len(full_df['generated_follow_up'].explode()) }\")\n",
    "full_df_valid_follow_up_only, full_invalid_questions = filterInvalidFollowUpQuestions(full_df.copy())\n",
    "print(f\"after filtering out all invalid follow up questions in FULL: {len(full_df_valid_follow_up_only['generated_follow_up'].explode())}\")\n",
    "\n",
    "print(f\"before filtering out all invalid follow up questions in GPT: {len(gpt_df['generated_follow_up'].explode())}\")\n",
    "gpt_df_valid_follow_up_only, gpt_invalid_questions = filterInvalidFollowUpQuestions(gpt_df.copy())\n",
    "print(f\"after filtering out all invalid follow up questions in GPT: {len(gpt_df_valid_follow_up_only['generated_follow_up'].explode())}\")\n",
    "\n",
    "print(f\"before filtering out all invalid follow up questions in ORG: {len(org_df['generated_follow_up'].explode())}\")\n",
    "org_df_valid_follow_up_only, org_invalid_questions = filterInvalidFollowUpQuestions(org_df.copy())\n",
    "print(f\"after filtering out all invalid follow up questions in ORG: {len(org_df_valid_follow_up_only['generated_follow_up'].explode())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['> Constant reflux can cause cancer of the sphincter.<QUS>  Is this true for people with GERD?', 'What about the Green Needle?', 'What about head injuries?', 'What about headphones with 40mm drivers?', 'What about the quieter planes?', 'What about jet engines?', 'But what about the quieter planes?', 'What about the time it takes to get from the airport to the gate?', \">Now try doing it for tomorrow's price chart.<QUS>.    >When you look at the historical chart of a company's price you'll be able to pick good buying and selling points 100% of the time.  >Now try to do it for today's price   Is that impossible?\", 'What about the daytrading side of things?', '>How exactly would it be easy to fix? You know how intricate a city‚Äôs traffic system is? And if the problem is with the hardware, you can‚Äôt solve a hardware problem with software.<QUS>.  How would it even be easy for a city to fix if it was so damn complicated?', \"What about a recipe that's not closely guarded?\", 'What about the spouses and children?', 'What about a reversed speaker?', 'What about the crust and mantle?', '>This paragraph has a <span>child element</span></p>   What does that mean?', 'What about the recycled screens?', 'So if I am drinking 8oz of a 10% beer and my girlfriend is drinking 16oz of 6% beer, who is getting more alcohol?', 'What about the emergency rooms?', 'What about the people who are selling the tickets to the concert?', 'What about a constant voltage oscillator?', 'What about static electricity?', 'What about self driving cars?', \"What about when it's a dog barking?\", 'What about people who are phobic?', '> \"Violet\" is weird because it is actually is a spectral color, it\\'s the lowest possible wavelength without being ultraviolet and thus invisible to the human eye. Because our eyes aren\\'t very sensitive to this wavelength \"true\" violet usually looks dark and hard to see.<QUS>  Is that why we perceive violet as green?', 'What about countries that have hyperinflation but the government doesn‚Äôt print money?', \"What about when you're not feeling hungry?\", 'But what about the vacuum?', 'What about the old currency?', 'What about bonds issued by other companies?', 'What about people who are not working?', '> Eventually that Fe hydroxide results in iron oxides.<QUS>.  Is it possible to remove Fe from water?', 'What about the people who are going to buy the cars?', 'What about the people who are not working?', 'So the amount of light coming in from the secondary mirror blocks the light coming out of the primary mirror?', 'What about black holes?', 'What about when the phone is fully charged?', 'What about people who are in space but not on the earth?', 'What about UV-A?', \">In almost any screen the pixels are constantly refreshing. This happens so fast it's invisible to the naked eye. But when you see it on many cameras you can catch the refresh in action.<QUS>    >When you see the refresh on many camera you can caught the refresh  in action.   How does this happen?   Does the camera refresh the pixels?  Does it refresh the entire screen?  Or is it just a few pixels at a time?\", '>Lizards just have genes that code for growing a tail back if it gets cut off in the same way you have genes for growing new skin when you cut your skin.<QUS>DNA.  Does that mean that lizards have a specific set of DNA that allows them to grow back their tail?', 'What about lizards that have been found to have been born without tail fins?', 'What about the more concentrated compounds?', 'But what about the other side?', '>If you watch phone screens before you sleep it is bad for your sleep. Because phone generates blue light(do some research on this). And you have to sleep before 10 pm(it is not might it is true). Get nature light during the day.<QUS>.  >Do you have a specific reason why this is bad?', \"But what about the stuff that's not used in the lab?\", 'What about redshift in the atmosphere?', 'What about the time it takes to pay the employees?', 'What if there are no other lanes?', 'What about supercriticality?', 'What about the money that was already in the bank?', 'But what about the bank?', \"But what about the people who don't want it?\", \"What about the people who don't have IDs?\", 'What about the plastic compound used in ziplock bags?', 'What about water and oil?', 'What about the plasma in blood?', 'But what about alcohol?', 'What about the other species?', 'What about a heated pool?', 'What about the scientists who are not in academia but do research in labs?', 'What about the apps that allow you to access your photos and media without permission?', 'What about windows 10 sandbox?', 'What about people who are not allergic?', '>By the time the Nazis were fully in charge, they had little left in the way of socialist policy whatsoever.<QUS>They got the name national socialist because early on they were a conglomeration of various nationalists and socialist groups.    How did the Nazis come to be in power?', 'What about those who are vaccinated?', \">It's all about more dense packaging to cram more circuit into the gizmo.<QUS> It's all for more dense packing to cram circuit into packaging  What does packaging have to do with packaging?\", \"But what about the people who are just there to 'lulz' others?\", 'What about the ones that are not \"tiny dick\"?', 'Thank you for the reply!    But what about the waste generated by wastewater treatment plants?', 'What about people who are color blind?', \"What about when there's too much honey?\", 'What about the inner and outer limits of the shadow?', 'What about women who want to be in tech but are not in the workforce?', 'But what about those who are still in the hospital when the procedure is performed?', 'What about the 6 week ban?', 'What about a ball filled with steel ball bearings?', 'What about medical malpractice?', 'What about the people who don‚Äôt have insurance?', \"What about people who don't have saccadic suppression?\", 'What about eating a burger?', 'What about reservists?', 'Ok, but what about the Navajo Code Talkers?', 'What about the ancient hunter gatherer societies?', 'What about the Rittenhouse case?', 'What about ground?', \"What about smaller companies that don't have a bank to audit?\", \"What about when you're sick?\", 'What about those that are not myelin?', 'What about ads?', '>Fun fact: It‚Äôs kind of common for cemetery workers to steal prosthetics here in Portugal as they are (or used to be) made of rare metals like platinum.<QUS>Basically the same as internal prosthetics. They go in the coffin and get taken out with the bones after the body had enough time to decompose.    >Fun fact, it‚Äôd kind of be common for grave workers to take prosthetics out of the coffins and sell them on the black market.  >What about the implants that were made of titanium?', '>There\\'s usually a \"project manager\" who\\'s in charge of precisely these things. They usually have a whole staff at their business who assist, get delegated to, check legal codes, draw up specific changes, take measurements, and yes, talk to businesses about what\\'s going on.<QUS>    Is there a manager in charge who can also oversee the actual construction of the road itself?   Or is that a job that is outsourced to a different company?  Or maybe it\\'s a combination of both?', \"But what about the smaller projects? Like the ones that don't need to be done on a regular basis?\", '>That goes with most safety regulations; you need to follow them for them to work.<QUS>.    What about the ones that say \"no live ammunition allowed on set\" or \"no guns allowed on the set\"   I\\'m not sure what those are supposed to mean.  I\\'ve seen them say \"use a prop gun\" but I\\'m assuming they\\'re talking about a prop?', 'What about the ocean floor?', 'What about people who have irregular sleep cycles?', 'What about the eyelashes?', 'What about light?', 'What about people who have never eaten meat before?', \"What about when you're not sick?\", 'What about a steak knife?', 'What about the case of the standard cable?', '> After you install the game you can go into your computers files and see everything that was downloaded.<QUS>It‚Äôs everything.  What?    What do you mean everything?', 'What if a roach or fly crawled into your ear and got stuck there?', '>Deserts also become quite cold at night with moisture turning to dampness which can be absorbed.  This gets absorbed before the hot sun comes back.<QUS>    >This gets absorbed by the hot Sun, but the cactus on my desk needs to be watered regularly.   How?', \">They don't know exactly what you owe. They have part of the information (your employer's and taxes paid by your employer, but they don't have the information about your items and other things you put in your tax return.<QUS>They have part, but not all, of the info.    So, if I owe $10,000, and I put $10k in my tax return and subtract $5,000 from my total income, I owe about $10K?\", 'But what if I owe the IRS a lot?', \"What about the things that I don't know about?\", 'What about submarines that are not in the water?', \">It should also be noted that photons aren't particles. Well, not quite particles, and also not quite waves. They have interesting properties since they're a particle-wave duality, like 2 photons being able to occupy the same exact spot. That's impossible with an actual physical particle.<QUS>That's impossible.    Why?  Because a particle is a wave.  What makes a wave a wave?\", 'Thank you for the answer!  But what about the electromagnetic field?', \"> It‚Äôs quite reasonable to argue that the US is overvalued / in a bubble fueled by tech and low rates and some of said growth is artificial.<QUS> This has been a huge driver of US growth recently.    I think it's fair to say that tech is a huge part of US economic growth, but I'm not convinced that it's the only driver.  I'd argue that other factors are also driving US economic strength, like innovation and competition.  If you look at the US vs EU GDP growth, the US has outpaced the EU by about 2 percentage points since 2000.  This is despite the fact that the EU has been growing at a much faster rate than the US.  So why is the US economy growing at such a rate?\", 'What about helicopters?', 'What about the deep sea cameras?', 'What about when we are standing still and then suddenly our whole body starts shaking violently?', 'If ground spices accumulate moisture, they will form clumps and harden. The best solution is to keep them in the fridge so they will not break down.<QUS>.  How do you soften them back?', \"What about the stuff that's in the fridge?\", \">Morally right and wrong is not black/white. It changes from culture to culture and over time. You can therefore not be 100% sure that you are right.    I think that's the key.  I'm not 100% certain that I am right, but I know that I'm somewhere close.  How do you know that?   How can you know if you're right?  How does anyone know that they're right, or that they are wrong?  >Do to others what you want others do to you   >I know that then I am somewhere close.<QUS>.  >How do you feel when you hear someone say something that is morally wrong?\", 'What about when you are disagreeing with someone?', 'What about people who disagree with me?', 'What about the absence of a number?', 'What about a vacuum?', '> So how do we smooth things? We take something abrasive like a file or sandpaper, and rub it on the rough thing. The metal will get smoother and smoother until it‚Äôs so smooth the light doesn‚Äôt scatter anymore.<QUS>    > Polish is really just super fine sandpaper as a paste.   How does it work?', 'What about carbon fiber?', 'What about the Heisman Trophy?', \"What about the ones that don't use cookies and don't collect data?\", 'What about the people who are not likely to be in your house?', 'But what about the advertisers who are able to use this data?', 'What about the old Atari ST?', 'What about a sphere?', 'Thanks for the answer!    But what about the heat generated by the heater?', 'What if there were a universe with a constant entropy?', 'What about inland areas like Texas?', 'What about the people who create their own Wikipedia pages?', \"What about chemical reactions that don't require oxygen?\", \">Being louder doesn't mean you're heard quicker, it means you're seen more prominently.<QUS>.  > Loudness is a measure of intensity not speed.   >Being louder means you‚Äôre heard more prominently.  Is that true?\", 'What about the people who were defrauded?', 'What about the people who were actually affected?', \">But for the overall question, it's mostly because we eat a lot of sugar. Bacteria that cause tooth decay absolutely thrive on sugar.<QUS>Well, start with the fact that we eat lots of sugar, and that's what causes decay.    >But for example,   *does* have to brush and floss?\", \"But what about dogs? They don't have to brush their teeth, right?\", 'What about amphetamines?', \">It can't see that time period because nothing can--the universe was an entirely opaque mass of super high stuff at that time. It wasn't until it had cooled down enough for proper matter to form that it became transparent and thus amenable to being seen with telescopes.<QUS>It wasn't transparent enough for the proper matter of the universe to form   How is that?\", '> Basically, on a restart, your computer \"empties the trash can,\" so you can start filling it up again, without constantly having to try to compact the trash to fit more in the can.<QUS>    >When that memory becomes more limited, your system struggles to try, find a place to fit even more stuff.\"   This is a misconception.   The trash can is not empty, it is just filled with unused memory.  The computer is trying to find a new spot for all the unused memory, but it can\\'t.  So it has to discard some of the unused RAM, and it will eventually run out of space.  This happens with most computers, but not all.  Why does it happen with some?', \"What about fish that don't have fins?\", 'What about UV-c and UV-b?', 'What about the ultraviolet (UV) radiation?', '> Not from the perspective of the outside observer anyways.<QUS>QUS?', 'What about a video game texture?', 'What about old school analog tape masters?', 'What about the COVID vaccine?', 'But what about the stuff that has been in production for a long time but has not been tested?', 'Thank you for the answer.    But what about the waste?', 'What about patents?', 'What about digital film?', 'What about reverb?', \">The torque (turning power) of the engine isn't enough at low revs to overcome the inertia of the vehicle, so the engine can't move it and is forced to stop.<QUS>.    Is this why when I shift into neutral the car stalls?\", \"What about the people who don't have glasses?\", 'But what about when stars are just dying?', \"What about the things we don't use, like our memories of our ancestors?\", 'What about stocks?', 'But what about the shows that don‚Äôt get picked up by a streaming service?', 'What about those flavored chewing gum that have a sugar content of 30% or 40% sugar?', 'What if I was swimming in a pool full of chlorine?', \"Thank you for the explanation. So, if I understand correctly, it's like a series of numbers, and the more numbers are found, the more coins are created?\", 'What about the curvature of spacetime?', \"What if you're not using headphones?\", '>When you touch a screen it completes and electrical circuit. You also absorb a small amount of electricity. Some devices may use that to determine if it is skin or something else based on the amount of electrical lost.<QUS>    >When you rub a screen, it completes  and electrical conduction.   How does it know that it is a pen and not a piece of paper?', 'Thanks for your answer! But what about the reverse?', 'What about a rocket?', 'What about in winter?', 'What about the other planets that are in the same plane?', \"What about the god Ba'al?\", '>The problem with this question is that shapes like spheres and cubes are three dimensional objects. Shapes like we think of them happen IN the universe, not to it.<QUS>.  How do we know this?', 'What about the stuff that happens when the membrane is completely dissolved, like proteins?', 'What about eating a bowl of chocolate every day?', 'Ok, but what about the people who are going to get the certificates?', 'What about websites that are hosted on AWS?', 'What about compressed zip files that contain a lot of redundant information?', \">Because all of the food now is riddled with terrible ingredients we have not evolved to eat naturally so some corporations can take in large profits.   I think that's a fair statement.  I'm not saying that corn is bad for you, I'm saying that it's bad for the environment.  We have been using corn for a long time now, and it's been around for thousands of years. The US was the first country to industrialize corn, and they did it for a very long time before that.  The US is still a corn based economy, and the US is a corn dependent economy, so why haven't we done more to reduce the amount of corn we have produced and make it less expensive to produce?  I don't think that the US has done enough to combat the over-consumption of corn, but I do think that we have made a lot of progress in reducing the amount we eat.  If we could do that, we would have less sugar and more protein.  Also, I think the US government should do more to combat addiction.  Like, if we could make it illegal to buy a pack of chips with a single sugar packet, we could stop people from eating them.  Or if we had a federal law that made it illegal for people to sell cigarettes, they could be taxed for smoking.  There are tons of other things that could be done to stop people addicted to cigarettes, like mandating that they use a specific flavors of cigarettes, and that are bad for your body.  And I think we need to do more research into the effects of these things.  For example, I've read a lot about the effects on the brain and the immune system. I think it's clear that smoking is bad, and addictive.  It's very hard to lose weight whenever you eat these foods because they cause inflammation, slow down metabolism, they wreak havoc on your insulin response, create what is known as the sugar trap (which is the idea that sugary foods make you hungrier and hungrier, as you eat more and more you never feel full, and a host of other biological issues that would not be present if we didn't have protections stopping the exploitations of these neurochemical responses to terrible foods that are addictive.<QUS>  I agree with you.  But I think I'm asking a different question.  Why is it so easy to gain weight and so hard to loose it and so damn hard to maintain it?\", '>The car dealership isn‚Äôt lending the money. If they can arrange for financing, the make money on the car and probably get a kickback, too.<QUS>.    How do they arrange for the financing?   Is it just a matter of getting the financing done?  Or is there a higher hurdle to getting the loan done?', 'What about people who have medical bankruptcy?', 'What about people who are really bad with money?', 'What about the cake analogy?', 'What about the factories?', \"What about when it's not an ingrown hair?\", 'Thank you for the answer, but what about those who have had their hair cut off?', 'What about Social Security?', '>Once connected together, power will flow across the connection as required to maintain synchronism.<QUS>  Is that why the generators are connected?', 'What about people with the highest chlorophyll levels?', 'What about capacitive touch screens?', 'What about the lid?', 'What about galaxies that are farting?', 'What about the cosmic microwave background?', 'But what about the sun?', 'What about planets and moons?', \"What about food that's frozen?\", 'But what about electricity on other planets?', 'But what about gravity?', 'What about planets that are completely obscured by the sun?', \"What about when you're wearing headphones with a built-in amplifier?\", 'What about the other side of the galaxy?', \"> But in short. If there is no observation or interaction, whatever just happened might as well not have ever existed.<QUS>  I don't know if it makes it any easier to understand when you accept the fact that time is not a thing, while also being a thing.   I think I phrased my question poorly. I meant that time exists between two things that interact. Is that correct?\", 'What about prequels?', 'What about smartphones?', 'But what about exercise and dieting for weight loss?', 'But what about cast iron?', 'But what about the cloud gaming providers that allow you to play games on your phone or tablet?', 'What about the devalued currency in other countries?', 'What about fats? Are they used as solvents for other things?', 'But what about the girls?', 'What about solid rocket motors? Are they held down by big clamps before launch?', 'What about the oil/gas wells that leak?', 'But what about people who have been trespasses before?', 'What about glass?', 'What about a lightning bolt that strikes a metal plate with a voltage of say 5.5V?', '>When you put a metal object in your mouth you\\'re creating an environment that is very similar to a weak battery.  This creates a very slight electrical current within your mouth  This is the same thing that happens when you put something in your saliva, but instead of a metal, it\\'s a weak, electrical current.  The end result is that your taste buds begin firing off randomly and generate the \"error\" taste that people typically associate with metal.<QUS>Why do we associate the taste of \"error\", with that of metal?', 'What about the higher end speakers?', 'What about the specific areas of the body?', 'What about sound waves?', 'What about the stunt pilots who are strapped to the back of a plane and take off?', 'What about.30-06?', '>Imagine one person counting 100 M&Ms for colors, or 10 people each doing 10 M&M. The same number of colors exist, but it takes a lot less time.<QUS>Multithreading is where software is made to use multiple threads.    How does this work?   Is it possible to run a program in parallel?  How do you tell which thread is running a program?  What are the benefits of having multiple processors running a single program?', \"What about when you're singing?\", 'Thanks for your answer. So if a company wants to buy back shares, it needs to be majority owned by the existing shareholders, right?', 'What about the field of philosophy?', 'What about the moon itself?', \"What about the horses' hooves that are not clipped?\", 'What about the original series?', 'What about private insurance?', \">Pretty much the only reason to land on an asteroid is to examine the asteroid itself.<QUS>Asteroids don't go to other galaxies. They simply swing around the solar system.    >Asteroid don't swing around our solar system, they simply swing  around the sun.  >   So if we could just send a space rover to an asteroid and land it there, we would eventually get to the Andromeda galaxy?\", 'What about a space probe?', \">Even at lightspeed, it would take 25,000 years to get there, and course no asteroid goes anywhere near that fast, so there's nothing we could put on an asteroid which could get to another galaxy.<QUS>   >Even at speed of light, it  would take  25,0000 years to reach another galaxy.    What?\", 'What about when the patient is already unconscious?', 'What about when you drink alcohol?', 'What about the matter that exists in space-time that is not being consumed?']\n"
     ]
    }
   ],
   "source": [
    "questions_ending_with_qmark = [q for q in org_invalid_questions if q[-1] == \"?\"]\n",
    "\n",
    "print(questions_ending_with_qmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Do they have any way to protect their eyes from sunburn?', 'I see. So if I rub my face with a towel, I can protect myself from sunburn?', 'But why don‚Äôt they have black spots?']\n",
      "['What causes cancer in the esophagus?', \"I see, thank you. So if the sphincter doesn't close properly, then the stomach acids can't get back up the esophagus?\", 'Is there any evidence that the sphincter can be closed without damage to the lining of the esophagus?', 'So if I have GERD, can I stop having heartburn?']\n",
      "['I think I phrased my question poorly. I meant, why didn‚Äôt the dwarves fight in the War of the Ring?', 'What about the dwarves? Did they fight in the war?']\n",
      "['>In a nutshell:  The sound waves are received by a microphone.  The microphone vibrates, and transforms the vibrations into an electrical signal.    This is how our voice is transmitted to other speakers, and how our words are received.  How does the electrical signal get converted into a vibration?', 'So how does the electrical signal get transmitted to the receiver?', 'Is there any way to reverse this?', 'Thanks for your answer!  So, if I say \"Hello\" and \"Hi\" in a loud voice, it will be heard by the receiver, and then turn into a vibration?']\n",
      "['So basically, you need to kill dragons to get to the end?', 'What is the endgame?', 'How does it work?', \"Ohh so it's like a video game but you can craft things in it?\"]\n",
      "['>You can write down the message or take a photo of the screen.   What about a screenshot of a text message?', 'How do you take screenshots of virtual machines?', 'I see, but how do you take screenshots of a bluescreen?', 'So if I have a screenshot enabled, how do I take a screenshot of it?']\n",
      "['>The Ben 10 toy that produces that sample (which correctly says ‚ÄúBrainstorm‚Äùas that is the name of the toy character) has a fairly low sample rate and a hanging frequency in the background.    Does this mean that the sound is not being played correctly?', 'So the question is, why does the sound have a hanging frequency?', 'But why does the background frequency hang?', 'How does it work?', 'Thanks for your answer!    But what about the Ben 10 song?  Does it have any relation to the real world?']\n",
      "[\"So if I see a white light in the air, it's not reflecting from another source?\", 'How do we know that it‚Äôs not reflecting from another source?', \"So if the object is so hot that it's absorbing the light, then how is it still reflecting?\", 'Is it possible to heat a torch up to a certain temperature and still see the light?', 'I see, but what about the black body radiation?']\n",
      "['How does the heart know how much blood to pump?', 'Thanks for your answer!    Does this mean that if I were to lose a lot of blood, my heart would beat faster to pump it to my brain?']\n",
      "[\">If you track 7 points, that's a 7-dimensional vector! Way more complicated than tiny little 4D quaternion.   What is a quaternions?\", 'So if I have a vector of 3d lines and rotate it once, it will turn into a 3d quaternion?', \"So if I have 7 points and rotate them left to right, how do I know that I'm in the correct quadrant?\", \"I see. So it's just a rotation problem?\"]\n",
      "['Is it possible to reproduce bass frequencies with headphones that are smaller than 40mm?']\n",
      "['>Voltage is a measure of potential difference. You‚Äôre not measuring the voltage of the positive or of the negative, you‚Äôm measuring the difference in electrical potential between the two.    So what does that mean?', 'So what is the difference between the two?', 'How does it measure the difference between the two?', 'So the voltage is measured by the difference between the two cells?', 'What is a \"voltage\" then?', 'So the voltage measure across a neuron is just the same voltage across the whole body?']\n",
      "['Is it possible to make a plane that is as fuel efficient as the one from the 60s?']\n",
      "[\">In the last 60 years the average burn dropped over 45%.which is an insane improvement.   How did this happen?    The answer is that technology has improved so much that the burning of fuel has decreased so much, that the amount of fuel burned has dropped so much the burning efficiency of fuel no longer matters.  The burning of fuels has dropped by so much because of the efficiency of the fuel used, that it no longer makes sense to burn more fuel.  So why isn't it burning more?\", \"So why isn't it going faster?\", 'Is it possible to go faster without sacrificing fuel efficiency?', 'Why is it that planes are not going faster?']\n",
      "['So the benefit of increased speed is marginal?', 'That makes sense. But why does it take so long?', 'But why is it the same for smaller planes?']\n",
      "[\"I think I phrased my question poorly. I meant, if you look at the historical price of a stock and then look at it again, how do you know if it's a buy or sell?\", \">Now try doing it for tomorrow's price chart    >Now try   What if you're a daytrader?\", 'Is it possible to use historical charts to make trades?', 'But how do they know when to sell?']\n",
      "['So the axis of rotation is what causes the star to appear stationary?', 'What part of the wheel remains stationary?', 'Thanks for the answer!   But how does it stay in line with the axis of rotation?', 'Is there any way we can tell where Polaris is located in the universe?', 'How does it appear to be moving away from us?', 'I see, but how does the center of the galaxy remain stationary?']\n",
      "[\"So it's not the hardware problem?\", 'Is there a software solution that could be implemented in a timely manner?', 'But why is that? Why is it so hard to fix?']\n",
      "['>Salt is a mineral which can dissolve in water.  So what happens to the salt that is dissolved in the water when it is evaporated?', 'So salt is just a mineral that can dissolve in water?', 'But why does it go back into the ocean?', 'I see, but why is it so salty?', 'Is it possible to make salt from brime and brine?']\n",
      "['I see, but what about the observer? Is there a way to know if they are experiencing the event in the past or in the future?', \"So if I'm in the future and I see a man in a suit and tie, is that event past or future?\", 'What about the observer who is not in the frame of reference? What does he see that the observer sees?', 'Is there any truth to this? I mean, if you can see past something, it\\'s not necessarily \"in the future\" right?']\n"
     ]
    }
   ],
   "source": [
    "for idx, sent in enumerate(org_df_valid_follow_up_only.loc[:20, \"generated_follow_up\"][:20]):\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Do they have any way to protect their eyes fr...\n",
       "1    [What causes cancer in the esophagus?, I see, ...\n",
       "2    [I think I phrased my question poorly. I meant...\n",
       "3    [>In a nutshell:  The sound waves are received...\n",
       "4    [So basically, you need to kill dragons to get...\n",
       "Name: generated_follow_up, dtype: object"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_df_valid_follow_up_only[\"generated_follow_up\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tkang/miniforge3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start working on model\n",
      "Evaluating distance threshold: 0.0...\n",
      "Task 3094 - Only 1 sample, skipping clustering.\n",
      "Evaluating distance threshold: 0.1...\n",
      "Task 3094 - Only 1 sample, skipping clustering.\n",
      "Evaluating distance threshold: 0.2...\n",
      "Task 3094 - Only 1 sample, skipping clustering.\n",
      "Evaluating distance threshold: 0.30000000000000004...\n",
      "Task 3094 - Only 1 sample, skipping clustering.\n",
      "Evaluating distance threshold: 0.4...\n",
      "Task 3094 - Only 1 sample, skipping clustering.\n",
      "Evaluating distance threshold: 0.5...\n",
      "Task 3094 - Only 1 sample, skipping clustering.\n",
      "Evaluating distance threshold: 0.6000000000000001...\n",
      "Task 3094 - Only 1 sample, skipping clustering.\n",
      "Evaluating distance threshold: 0.7000000000000001...\n",
      "Task 3094 - Only 1 sample, skipping clustering.\n",
      "Evaluating distance threshold: 0.8...\n",
      "Task 3094 - Only 1 sample, skipping clustering.\n",
      "Evaluating distance threshold: 0.9...\n",
      "Task 3094 - Only 1 sample, skipping clustering.\n",
      "Evaluating distance threshold: 1.0...\n",
      "Task 3094 - Only 1 sample, skipping clustering.\n",
      "Start working on model\n",
      "Evaluating distance threshold: 0.0...\n",
      "Task 3032 - Only 1 sample, skipping clustering.\n",
      "Task 3219 - Only 1 sample, skipping clustering.\n",
      "Task 3311 - Only 1 sample, skipping clustering.\n",
      "Task 3326 - Only 1 sample, skipping clustering.\n",
      "Task 3359 - Only 1 sample, skipping clustering.\n",
      "Task 3393 - Only 1 sample, skipping clustering.\n",
      "Task 3410 - Only 1 sample, skipping clustering.\n",
      "Evaluating distance threshold: 0.1...\n",
      "Task 3032 - Only 1 sample, skipping clustering.\n",
      "Task 3219 - Only 1 sample, skipping clustering.\n",
      "Task 3311 - Only 1 sample, skipping clustering.\n",
      "Task 3326 - Only 1 sample, skipping clustering.\n",
      "Task 3359 - Only 1 sample, skipping clustering.\n",
      "Task 3393 - Only 1 sample, skipping clustering.\n",
      "Task 3410 - Only 1 sample, skipping clustering.\n",
      "Evaluating distance threshold: 0.2...\n",
      "Task 3032 - Only 1 sample, skipping clustering.\n",
      "Task 3219 - Only 1 sample, skipping clustering.\n",
      "Task 3311 - Only 1 sample, skipping clustering.\n",
      "Task 3326 - Only 1 sample, skipping clustering.\n",
      "Task 3359 - Only 1 sample, skipping clustering.\n",
      "Task 3393 - Only 1 sample, skipping clustering.\n",
      "Task 3410 - Only 1 sample, skipping clustering.\n",
      "Evaluating distance threshold: 0.30000000000000004...\n",
      "Task 3032 - Only 1 sample, skipping clustering.\n",
      "Task 3219 - Only 1 sample, skipping clustering.\n",
      "Task 3311 - Only 1 sample, skipping clustering.\n",
      "Task 3326 - Only 1 sample, skipping clustering.\n",
      "Task 3359 - Only 1 sample, skipping clustering.\n",
      "Task 3393 - Only 1 sample, skipping clustering.\n",
      "Task 3410 - Only 1 sample, skipping clustering.\n",
      "Evaluating distance threshold: 0.4...\n",
      "Task 3032 - Only 1 sample, skipping clustering.\n",
      "Task 3219 - Only 1 sample, skipping clustering.\n",
      "Task 3311 - Only 1 sample, skipping clustering.\n",
      "Task 3326 - Only 1 sample, skipping clustering.\n",
      "Task 3359 - Only 1 sample, skipping clustering.\n",
      "Task 3393 - Only 1 sample, skipping clustering.\n",
      "Task 3410 - Only 1 sample, skipping clustering.\n",
      "Evaluating distance threshold: 0.5...\n",
      "Task 3032 - Only 1 sample, skipping clustering.\n",
      "Task 3219 - Only 1 sample, skipping clustering.\n",
      "Task 3311 - Only 1 sample, skipping clustering.\n",
      "Task 3326 - Only 1 sample, skipping clustering.\n",
      "Task 3359 - Only 1 sample, skipping clustering.\n",
      "Task 3393 - Only 1 sample, skipping clustering.\n",
      "Task 3410 - Only 1 sample, skipping clustering.\n",
      "Evaluating distance threshold: 0.6000000000000001...\n",
      "Task 3032 - Only 1 sample, skipping clustering.\n",
      "Task 3219 - Only 1 sample, skipping clustering.\n",
      "Task 3311 - Only 1 sample, skipping clustering.\n",
      "Task 3326 - Only 1 sample, skipping clustering.\n",
      "Task 3359 - Only 1 sample, skipping clustering.\n",
      "Task 3393 - Only 1 sample, skipping clustering.\n",
      "Task 3410 - Only 1 sample, skipping clustering.\n",
      "Evaluating distance threshold: 0.7000000000000001...\n",
      "Task 3032 - Only 1 sample, skipping clustering.\n",
      "Task 3219 - Only 1 sample, skipping clustering.\n",
      "Task 3311 - Only 1 sample, skipping clustering.\n",
      "Task 3326 - Only 1 sample, skipping clustering.\n",
      "Task 3359 - Only 1 sample, skipping clustering.\n",
      "Task 3393 - Only 1 sample, skipping clustering.\n",
      "Task 3410 - Only 1 sample, skipping clustering.\n",
      "Evaluating distance threshold: 0.8...\n",
      "Task 3032 - Only 1 sample, skipping clustering.\n",
      "Task 3219 - Only 1 sample, skipping clustering.\n",
      "Task 3311 - Only 1 sample, skipping clustering.\n",
      "Task 3326 - Only 1 sample, skipping clustering.\n",
      "Task 3359 - Only 1 sample, skipping clustering.\n",
      "Task 3393 - Only 1 sample, skipping clustering.\n",
      "Task 3410 - Only 1 sample, skipping clustering.\n",
      "Evaluating distance threshold: 0.9...\n",
      "Task 3032 - Only 1 sample, skipping clustering.\n",
      "Task 3219 - Only 1 sample, skipping clustering.\n",
      "Task 3311 - Only 1 sample, skipping clustering.\n",
      "Task 3326 - Only 1 sample, skipping clustering.\n",
      "Task 3359 - Only 1 sample, skipping clustering.\n",
      "Task 3393 - Only 1 sample, skipping clustering.\n",
      "Task 3410 - Only 1 sample, skipping clustering.\n",
      "Evaluating distance threshold: 1.0...\n",
      "Task 3032 - Only 1 sample, skipping clustering.\n",
      "Task 3219 - Only 1 sample, skipping clustering.\n",
      "Task 3311 - Only 1 sample, skipping clustering.\n",
      "Task 3326 - Only 1 sample, skipping clustering.\n",
      "Task 3359 - Only 1 sample, skipping clustering.\n",
      "Task 3393 - Only 1 sample, skipping clustering.\n",
      "Task 3410 - Only 1 sample, skipping clustering.\n",
      "Start working on model\n",
      "Evaluating distance threshold: 0.0...\n",
      "Task 3010 - Only 1 sample, skipping clustering.\n",
      "Task 3012 - Only 1 sample, skipping clustering.\n",
      "Task 3036 - Only 1 sample, skipping clustering.\n",
      "Task 3117 - Only 1 sample, skipping clustering.\n",
      "Task 3247 - Only 1 sample, skipping clustering.\n",
      "Task 3262 - Only 1 sample, skipping clustering.\n",
      "Task 3431 - Only 1 sample, skipping clustering.\n",
      "Task 3477 - Only 1 sample, skipping clustering.\n",
      "Task 3482 - Only 1 sample, skipping clustering.\n",
      "Evaluating distance threshold: 0.1...\n",
      "Task 3010 - Only 1 sample, skipping clustering.\n",
      "Task 3012 - Only 1 sample, skipping clustering.\n",
      "Task 3036 - Only 1 sample, skipping clustering.\n",
      "Task 3117 - Only 1 sample, skipping clustering.\n",
      "Task 3247 - Only 1 sample, skipping clustering.\n",
      "Task 3262 - Only 1 sample, skipping clustering.\n",
      "Task 3431 - Only 1 sample, skipping clustering.\n",
      "Task 3477 - Only 1 sample, skipping clustering.\n",
      "Task 3482 - Only 1 sample, skipping clustering.\n",
      "Evaluating distance threshold: 0.2...\n",
      "Task 3010 - Only 1 sample, skipping clustering.\n",
      "Task 3012 - Only 1 sample, skipping clustering.\n",
      "Task 3036 - Only 1 sample, skipping clustering.\n",
      "Task 3117 - Only 1 sample, skipping clustering.\n",
      "Task 3247 - Only 1 sample, skipping clustering.\n",
      "Task 3262 - Only 1 sample, skipping clustering.\n",
      "Task 3431 - Only 1 sample, skipping clustering.\n",
      "Task 3477 - Only 1 sample, skipping clustering.\n",
      "Task 3482 - Only 1 sample, skipping clustering.\n",
      "Evaluating distance threshold: 0.30000000000000004...\n",
      "Task 3010 - Only 1 sample, skipping clustering.\n",
      "Task 3012 - Only 1 sample, skipping clustering.\n",
      "Task 3036 - Only 1 sample, skipping clustering.\n",
      "Task 3117 - Only 1 sample, skipping clustering.\n",
      "Task 3247 - Only 1 sample, skipping clustering.\n",
      "Task 3262 - Only 1 sample, skipping clustering.\n",
      "Task 3431 - Only 1 sample, skipping clustering.\n",
      "Task 3477 - Only 1 sample, skipping clustering.\n",
      "Task 3482 - Only 1 sample, skipping clustering.\n",
      "Evaluating distance threshold: 0.4...\n",
      "Task 3010 - Only 1 sample, skipping clustering.\n",
      "Task 3012 - Only 1 sample, skipping clustering.\n",
      "Task 3036 - Only 1 sample, skipping clustering.\n",
      "Task 3117 - Only 1 sample, skipping clustering.\n",
      "Task 3247 - Only 1 sample, skipping clustering.\n",
      "Task 3262 - Only 1 sample, skipping clustering.\n",
      "Task 3431 - Only 1 sample, skipping clustering.\n",
      "Task 3477 - Only 1 sample, skipping clustering.\n",
      "Task 3482 - Only 1 sample, skipping clustering.\n",
      "Evaluating distance threshold: 0.5...\n",
      "Task 3010 - Only 1 sample, skipping clustering.\n",
      "Task 3012 - Only 1 sample, skipping clustering.\n",
      "Task 3036 - Only 1 sample, skipping clustering.\n",
      "Task 3117 - Only 1 sample, skipping clustering.\n",
      "Task 3247 - Only 1 sample, skipping clustering.\n",
      "Task 3262 - Only 1 sample, skipping clustering.\n",
      "Task 3431 - Only 1 sample, skipping clustering.\n",
      "Task 3477 - Only 1 sample, skipping clustering.\n",
      "Task 3482 - Only 1 sample, skipping clustering.\n",
      "Evaluating distance threshold: 0.6000000000000001...\n",
      "Task 3010 - Only 1 sample, skipping clustering.\n",
      "Task 3012 - Only 1 sample, skipping clustering.\n",
      "Task 3036 - Only 1 sample, skipping clustering.\n",
      "Task 3117 - Only 1 sample, skipping clustering.\n",
      "Task 3247 - Only 1 sample, skipping clustering.\n",
      "Task 3262 - Only 1 sample, skipping clustering.\n",
      "Task 3431 - Only 1 sample, skipping clustering.\n",
      "Task 3477 - Only 1 sample, skipping clustering.\n",
      "Task 3482 - Only 1 sample, skipping clustering.\n",
      "Evaluating distance threshold: 0.7000000000000001...\n",
      "Task 3010 - Only 1 sample, skipping clustering.\n",
      "Task 3012 - Only 1 sample, skipping clustering.\n",
      "Task 3036 - Only 1 sample, skipping clustering.\n",
      "Task 3117 - Only 1 sample, skipping clustering.\n",
      "Task 3247 - Only 1 sample, skipping clustering.\n",
      "Task 3262 - Only 1 sample, skipping clustering.\n",
      "Task 3431 - Only 1 sample, skipping clustering.\n",
      "Task 3477 - Only 1 sample, skipping clustering.\n",
      "Task 3482 - Only 1 sample, skipping clustering.\n",
      "Evaluating distance threshold: 0.8...\n",
      "Task 3010 - Only 1 sample, skipping clustering.\n",
      "Task 3012 - Only 1 sample, skipping clustering.\n",
      "Task 3036 - Only 1 sample, skipping clustering.\n",
      "Task 3117 - Only 1 sample, skipping clustering.\n",
      "Task 3247 - Only 1 sample, skipping clustering.\n",
      "Task 3262 - Only 1 sample, skipping clustering.\n",
      "Task 3431 - Only 1 sample, skipping clustering.\n",
      "Task 3477 - Only 1 sample, skipping clustering.\n",
      "Task 3482 - Only 1 sample, skipping clustering.\n",
      "Evaluating distance threshold: 0.9...\n",
      "Task 3010 - Only 1 sample, skipping clustering.\n",
      "Task 3012 - Only 1 sample, skipping clustering.\n",
      "Task 3036 - Only 1 sample, skipping clustering.\n",
      "Task 3117 - Only 1 sample, skipping clustering.\n",
      "Task 3247 - Only 1 sample, skipping clustering.\n",
      "Task 3262 - Only 1 sample, skipping clustering.\n",
      "Task 3431 - Only 1 sample, skipping clustering.\n",
      "Task 3477 - Only 1 sample, skipping clustering.\n",
      "Task 3482 - Only 1 sample, skipping clustering.\n",
      "Evaluating distance threshold: 1.0...\n",
      "Task 3010 - Only 1 sample, skipping clustering.\n",
      "Task 3012 - Only 1 sample, skipping clustering.\n",
      "Task 3036 - Only 1 sample, skipping clustering.\n",
      "Task 3117 - Only 1 sample, skipping clustering.\n",
      "Task 3247 - Only 1 sample, skipping clustering.\n",
      "Task 3262 - Only 1 sample, skipping clustering.\n",
      "Task 3431 - Only 1 sample, skipping clustering.\n",
      "Task 3477 - Only 1 sample, skipping clustering.\n",
      "Task 3482 - Only 1 sample, skipping clustering.\n",
      "Clustering complete for all models.\n"
     ]
    }
   ],
   "source": [
    "### cluster by similar follow up questions\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "\n",
    "embedder = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "models = [full_df_valid_follow_up_only, gpt_df_valid_follow_up_only, org_df_valid_follow_up_only]\n",
    "model_names = [\"full\", \"gpt\", \"org\"]\n",
    "distance_thresholds = np.arange(0, 1.1, 0.1)\n",
    "# distance_thresholds = [0,1]\n",
    "clustered_models = []\n",
    "\n",
    "for idx in range(len(models)):\n",
    "    print(\"Start working on model\")\n",
    "    model_name = model_names[idx]\n",
    "    data = models[idx].copy()\n",
    "\n",
    "    # Loop over all rows in the dataset\n",
    "    for dt in distance_thresholds:\n",
    "        print(f\"Evaluating distance threshold: {dt}...\")\n",
    "        # Store clustered follow-up questions\n",
    "        clustered_follow_ups = []\n",
    "        clustered_follow_ups_count = []\n",
    "\n",
    "        for index, row in data.iterrows():\n",
    "            task_id = row['id']\n",
    "            current_corpus = row[\"generated_follow_up\"]\n",
    "\n",
    "            # print(f\"Current corpus has {len(current_corpus)} different follow up questions\")\n",
    "\n",
    "            # Ensure it's a list (not a single string)\n",
    "            if isinstance(current_corpus, str):\n",
    "                current_corpus = [current_corpus]\n",
    "            elif not isinstance(current_corpus, list):\n",
    "                print(f\"Skipping task {task_id} due to invalid format.\")\n",
    "                clustered_follow_ups.append([])\n",
    "                clustered_follow_ups_count.append(0)\n",
    "                continue\n",
    "\n",
    "            if len(current_corpus) == 1:\n",
    "                clustered_follow_ups.append(current_corpus)  # Keep as is\n",
    "                clustered_follow_ups_count.append(1)  # Single item cluster\n",
    "                print(f\"Task {task_id} - Only 1 sample, skipping clustering.\")\n",
    "                continue\n",
    "\n",
    "            # Convert sentences to embeddings\n",
    "            corpus_embeddings = embedder.encode(current_corpus)\n",
    "\n",
    "            # Perform agglomerative clustering\n",
    "            clustering_model = AgglomerativeClustering(\n",
    "                metric='cosine', linkage='average',\n",
    "                n_clusters=None, distance_threshold=dt\n",
    "            ) \n",
    "            clustering_model.fit(corpus_embeddings)\n",
    "            cluster_assignment = clustering_model.labels_\n",
    "\n",
    "            # Organize clustered sentences\n",
    "            clustered_sentences = {}\n",
    "            for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
    "                if cluster_id not in clustered_sentences:\n",
    "                    clustered_sentences[cluster_id] = []\n",
    "                clustered_sentences[cluster_id].append(current_corpus[sentence_id])\n",
    "\n",
    "            # Collect all clustered follow-ups\n",
    "            clustered_list = list(clustered_sentences.values())\n",
    "\n",
    "            # Append clustered results to columns\n",
    "            clustered_follow_ups.append(clustered_list)\n",
    "            clustered_follow_ups_count.append(len(clustered_list))\n",
    "\n",
    "            # print(f\"Task {task_id} Completed - {len(clustered_list)} clusters found.\")\n",
    "\n",
    "        # Add new columns to DataFrame\n",
    "        data[f\"clustered_dt_{dt}\"] = clustered_follow_ups\n",
    "        data[f\"clustered_count_dt_{dt}\"] = clustered_follow_ups_count\n",
    "\n",
    "    clustered_models.append(data)\n",
    "\n",
    "print(\"Clustering complete for all models.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clustered_full = pd.DataFrame(clustered_models[0])\n",
    "df_clustered_gpt = pd.DataFrame(clustered_models[1])\n",
    "df_clustered_org = pd.DataFrame(clustered_models[2])\n",
    "average_cluster_count_per_dt = {\n",
    "    \"full\": [],\n",
    "    \"gpt\": [],\n",
    "    \"org\": []\n",
    "}\n",
    "\n",
    "for model_i in range(3):\n",
    "    l = []\n",
    "    for i in distance_thresholds:\n",
    "        l.append(clustered_models[model_i][f\"clustered_count_dt_{i}\"].mean())\n",
    "    average_cluster_count_per_dt[model_names[model_i]] = l\n",
    "\n",
    "# df_clustered_full[\"generated_follow_ups_clustered_count\"]\n",
    "\n",
    "# temp = df_clustered_full[df_clustered_full[\"generated_follow_ups_clustered_count\"] > 1]\n",
    "# for group in temp[\"generated_follow_ups_clustered\"]:\n",
    "#     print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'full': [3.904191616766467,\n",
       "  3.904191616766467,\n",
       "  3.8842315369261478,\n",
       "  3.69061876247505,\n",
       "  3.165668662674651,\n",
       "  2.4291417165668663,\n",
       "  1.7305389221556886,\n",
       "  1.2614770459081837,\n",
       "  1.0678642714570858,\n",
       "  1.0119760479041917,\n",
       "  1.001996007984032],\n",
       " 'gpt': [3.654690618762475,\n",
       "  3.654690618762475,\n",
       "  3.632734530938124,\n",
       "  3.4011976047904193,\n",
       "  2.784431137724551,\n",
       "  2.059880239520958,\n",
       "  1.4850299401197604,\n",
       "  1.1397205588822354,\n",
       "  1.031936127744511,\n",
       "  1.003992015968064,\n",
       "  1.0],\n",
       " 'org': [3.730538922155689,\n",
       "  3.730538922155689,\n",
       "  3.722554890219561,\n",
       "  3.626746506986028,\n",
       "  3.3473053892215567,\n",
       "  2.852295409181637,\n",
       "  2.2574850299401197,\n",
       "  1.7305389221556886,\n",
       "  1.3592814371257484,\n",
       "  1.127744510978044,\n",
       "  1.0079840319361277]}"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdxaxa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cluster Count for Distance Threshold (0.0):\n",
      "Model full: 3.904191616766467\n",
      "Model gpt: 3.654690618762475\n",
      "Model org: 3.730538922155689\n",
      "\n",
      "\n",
      "Average Cluster Count for Distance Threshold (0.1):\n",
      "Model full: 3.904191616766467\n",
      "Model gpt: 3.654690618762475\n",
      "Model org: 3.730538922155689\n",
      "\n",
      "\n",
      "Average Cluster Count for Distance Threshold (0.2):\n",
      "Model full: 3.8842315369261478\n",
      "Model gpt: 3.632734530938124\n",
      "Model org: 3.722554890219561\n",
      "\n",
      "\n",
      "Average Cluster Count for Distance Threshold (0.30000000000000004):\n",
      "Model full: 3.69061876247505\n",
      "Model gpt: 3.4011976047904193\n",
      "Model org: 3.626746506986028\n",
      "\n",
      "\n",
      "Average Cluster Count for Distance Threshold (0.4):\n",
      "Model full: 3.165668662674651\n",
      "Model gpt: 2.784431137724551\n",
      "Model org: 3.3473053892215567\n",
      "\n",
      "\n",
      "Average Cluster Count for Distance Threshold (0.5):\n",
      "Model full: 2.4291417165668663\n",
      "Model gpt: 2.059880239520958\n",
      "Model org: 2.852295409181637\n",
      "\n",
      "\n",
      "Average Cluster Count for Distance Threshold (0.6000000000000001):\n",
      "Model full: 1.7305389221556886\n",
      "Model gpt: 1.4850299401197604\n",
      "Model org: 2.2574850299401197\n",
      "\n",
      "\n",
      "Average Cluster Count for Distance Threshold (0.7000000000000001):\n",
      "Model full: 1.2614770459081837\n",
      "Model gpt: 1.1397205588822354\n",
      "Model org: 1.7305389221556886\n",
      "\n",
      "\n",
      "Average Cluster Count for Distance Threshold (0.8):\n",
      "Model full: 1.0678642714570858\n",
      "Model gpt: 1.031936127744511\n",
      "Model org: 1.3592814371257484\n",
      "\n",
      "\n",
      "Average Cluster Count for Distance Threshold (0.9):\n",
      "Model full: 1.0119760479041917\n",
      "Model gpt: 1.003992015968064\n",
      "Model org: 1.127744510978044\n",
      "\n",
      "\n",
      "Average Cluster Count for Distance Threshold (1.0):\n",
      "Model full: 1.001996007984032\n",
      "Model gpt: 1.0\n",
      "Model org: 1.0079840319361277\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    print(f\"Average Cluster Count for Distance Threshold ({distance_thresholds[i]}):\")\n",
    "    for model, values in average_cluster_count_per_dt.items():\n",
    "        print(f\"Model {model}: {values[i]}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Number of Unique Follow Up Questions (Clusters) for Full Dataset: 3.165668662674651\n",
      "Average Number of Unique Follow Up Questions (Clusters) for ORG Dataset: 3.3473053892215567\n",
      "Average Number of Unique Follow Up Questions (Clusters) for GPT Dataset: 2.784431137724551\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average number of clusters for each OQ/OA pair\n",
    "mean_cluster_count_full_df = df_clustered_full[\"generated_follow_ups_clustered_count\"].mean()\n",
    "mean_cluster_count_org_df = df_clustered_org[\"generated_follow_ups_clustered_count\"].mean()\n",
    "mean_cluster_count_gpt_df = df_clustered_gpt[\"generated_follow_ups_clustered_count\"].mean()\n",
    "\n",
    "print(f\"Average Number of Unique Follow Up Questions (Clusters) for Full Dataset: {mean_cluster_count_full_df}\")\n",
    "print(f\"Average Number of Unique Follow Up Questions (Clusters) for ORG Dataset: {mean_cluster_count_org_df}\")\n",
    "print(f\"Average Number of Unique Follow Up Questions (Clusters) for GPT Dataset: {mean_cluster_count_gpt_df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501\n",
      "474\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package nps_chat to /Users/tkang/nltk_data...\n",
      "[nltk_data]   Package nps_chat is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.76049675 0.74630396 0.7439385  0.73491124 0.73727811]\n",
      "Mean Accuracy: 0.7445857113363823\n"
     ]
    }
   ],
   "source": [
    "# import nltk\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# # Download dataset\n",
    "# nltk.download('nps_chat')\n",
    "# posts = nltk.corpus.nps_chat.xml_posts()\n",
    "\n",
    "# # Extract text and labels\n",
    "# posts_text = [post.text for post in posts]\n",
    "# y = [post.get('class') for post in posts]\n",
    "\n",
    "# # Split into train and test (80-20 split)\n",
    "# train_text = posts_text[:int(len(posts_text) * 0.8)]\n",
    "# test_text = posts_text[int(len(posts_text) * 0.2):]\n",
    "\n",
    "# y_train = y[:int(len(posts_text) * 0.8)]\n",
    "# y_test = y[int(len(posts_text) * 0.2):]\n",
    "\n",
    "# # Get TF-IDF features\n",
    "# vectorizer = TfidfVectorizer(ngram_range=(1,3), \n",
    "#                              min_df=0.001, \n",
    "#                              max_df=0.7, \n",
    "#                              analyzer='word')\n",
    "\n",
    "# X_train = vectorizer.fit_transform(train_text)\n",
    "# X_test = vectorizer.transform(test_text)\n",
    "\n",
    "# # Define classifier\n",
    "# gb = GradientBoostingClassifier(n_estimators=400, random_state=0)\n",
    "\n",
    "# # Use 5-fold cross-validation on the training set\n",
    "# cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# cv_scores = cross_val_score(gb, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# # Print cross-validation results\n",
    "# print(\"Cross-Validation Scores:\", cv_scores)\n",
    "# print(\"Mean Accuracy:\", cv_scores.mean())\n",
    "\n",
    "# gb.fit(X_train, y_train)\n",
    "\n",
    "# predictions_rf = gb.predict(X_test)\n",
    "\n",
    "# #Accuracy of 86% not bad\n",
    "# print(classification_report(y_test, predictions_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
